# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Eo_dgMx3WCHY0prZGC06ADziqs11Ca49

# ***DID BY ME HARIRAM
FOR ANY QURIES MAIL ME ( [Email](mailto:hariramhdmp@gmail.com))***

# Predicting international movie box office revenue

**The main goal of this project was to come up with a model to predict the international box office revenue of a movie based off a number of known data. A model like this could be useful for production companies or studios to decide what kinds of movies to make, for distributors to estimate how much money to dedicate to marketing, or for cinemas to know more about the types of movies that make the most money.**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import statsmodels.api as sm
from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PolynomialFeatures

top1000 = pd.read_pickle('/top1000.pkl')
top1000.head()

movies_intl = top1000.drop(['url_slug','domestic_gross','distributor'], axis=1)
movies_intl.reset_index(inplace=True)
movies_intl.head()

"""**I need to use MultiLabelBinarizer to turn the genre column (of lists) into their individual columns**.bold text"""

mlb = MultiLabelBinarizer()
genres = pd.DataFrame(mlb.fit_transform(movies_intl['genre']),columns=mlb.classes_)
movies_intl = pd.merge(movies_intl, genres, left_index=True, right_index=True)
movies_intl.head()

movies_intl = movies_intl.drop(['genre'], axis=1)
movies_intl.set_index('index',inplace=True)
movies_intl.head()

movies_intl['rating'].value_counts()

movies_intl = movies_intl.replace('Approved', np.NaN).dropna()

movies_intl

"""**I'm using pd.get_dummies to give each MPAA rating its own column as well.**"""

#pd.get_dummies for the rating column (the only remaining column that isn't numerical)
movies_intl = pd.get_dummies(movies_intl)
movies_intl.head()

"""**After some regression experimentation, I'm dropping the top three movies because they're huge outliers.**"""

movies_intl.drop(['Avengers: Endgame', 'Avatar', 'Titanic'])

movies_intl.corr()

movies_intl.columns

"""**Simple Validation**"""

X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)

"""**Standard Linear Regression**"""

lr = LinearRegression()
lr.fit(X_train, y_train)
lr.score(X_train, y_train)

lr.score(X_val,y_val)

"""**Polynomial**"""

poly = PolynomialFeatures(degree=2) 

X_train_poly = poly.fit_transform(X_train)
X_val_poly = poly.transform(X_val)

lm_poly = LinearRegression()
lm_poly.fit(X_train_poly, y_train)
lm_poly.score(X_train_poly, y_train)

lm_poly.score(X_val_poly, y_val)     #bad score here!

"""**Ridge**"""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

lm_reg = Ridge(alpha=1)
lm_reg.fit(X_train_scaled, y_train)
lm_reg.score(X_train_scaled, y_train)

lm_reg.score(X_val_scaled, y_val)

"""**Ridge (with new alpha values - I did this many times)**"""

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

lm_ridge = Ridge(alpha=100)
lm_ridge.fit(X_train_scaled, y_train)
lm_ridge.score(X_train_scaled, y_train)

lm_ridge.score(X_val_scaled, y_val)

"""**Eliminating Features with Lasso CV**"""

lm_lasso = LassoCV(cv=4)
lm_lasso.fit(X_train_scaled, y_train)
lm_lasso.score(X_train_scaled, y_train)

lm_lasso.score(X_val_scaled, y_val)

list(zip(X_train.columns, lm_lasso.coef_))

movies_intl = movies_intl.drop(['Documentary', 'Drama','Romance','Sci-Fi','rating_R'], axis=1)
X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)

lm_lasso = LassoCV(cv=4)
lm_lasso.fit(X_train_scaled, y_train)
lm_lasso.score(X_train_scaled, y_train)

lm_lasso.score(X_val_scaled, y_val)

list(zip(X_train.columns, lm_lasso.coef_))

movies_intl = movies_intl.drop(['Family','Fantasy','War','Western'], axis=1)
X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)

lm_lasso = LassoCV(cv=4)
lm_lasso.fit(X_train_scaled, y_train)
lm_lasso.score(X_train_scaled, y_train)

lm_lasso.score(X_val_scaled, y_val)

list(zip(X_train.columns, lm_lasso.coef_))

movies_intl = movies_intl.drop(['History','Horror','Sport','rating_PG-13'], axis=1)
X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)

lm_lasso = LassoCV(cv=4)
lm_lasso.fit(X_train_scaled, y_train)
lm_lasso.score(X_train_scaled, y_train)

lm_lasso.score(X_val_scaled, y_val)

list(zip(X_train.columns, lm_lasso.coef_))

movies_intl = movies_intl.drop(['Music','Musical','rating_PG'], axis=1)
X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)

lm_lasso = LassoCV(cv=4)
lm_lasso.fit(X_train_scaled, y_train)
lm_lasso.score(X_train_scaled, y_train)

lm_lasso.score(X_val_scaled, y_val)

list(zip(X_train.columns, lm_lasso.coef_))

X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)

lm_lasso = LassoCV()
lm_lasso.fit(X_train_scaled, y_train)
lm_lasso.score(X_train_scaled, y_train)

lm_lasso.score(X_val_scaled, y_val)

list(zip(X_train.columns, lm_lasso.coef_))

"""**Cross Validation**"""

from sklearn.model_selection import KFold

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10) #hold out 20% of the data for final testing

X, y = np.array(X), np.array(y)
kf = KFold(n_splits=5, shuffle=True, random_state =71)
cv_lm_r2s, cv_lm_ridge_r2s, cv_lm_ridgetrain_r2s, cv_lm_lasso_r2s, cv_lm_lassotrain_r2s = [], [], [], [], []     #collect the validation results for all models

for train_ind, val_ind in kf.split(X,y):
    
    X_train, y_train = X[train_ind], y[train_ind]
    X_val, y_val = X[val_ind], y[val_ind] 
    
    lm = LinearRegression()
    lm_ridge = RidgeCV()
    lm_lasso = LassoCV()
    
    lm.fit(X_train, y_train)
    cv_lm_r2s.append(lm.score(X_val, y_val))
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    
    lm_ridge.fit(X_train_scaled, y_train)
    cv_lm_ridge_r2s.append(lm_ridge.score(X_train_scaled, y_train))
    cv_lm_ridgetrain_r2s.append(lm_ridge.score(X_val_scaled, y_val))
    
    lm_lasso.fit(X_train_scaled, y_train)
    cv_lm_lasso_r2s.append(lm_lasso.score(X_train_scaled, y_train))
    cv_lm_lassotrain_r2s.append(lm_lasso.score(X_val_scaled, y_val))

print('Simple regression scores: ', cv_lm_r2s)
print('Ridge scores: Train:', cv_lm_ridgetrain_r2s, 'Val: ', cv_lm_ridge_r2s)
print('Lasso scores: Train', cv_lm_lassotrain_r2s, 'Val: ', cv_lm_lasso_r2s, '\n')

print(f'Simple mean cv r^2: {np.mean(cv_lm_r2s):.3f} +- {np.std(cv_lm_r2s):.3f}')
print(f'Ridge Train mean cv r^2: {np.mean(cv_lm_ridgetrain_r2s):.3f} +- {np.std(cv_lm_ridgetrain_r2s):.3f}')
print(f'Ridge Val mean cv r^2: {np.mean(cv_lm_ridge_r2s):.3f} +- {np.std(cv_lm_ridge_r2s):.3f}')
print(f'Lasso Train mean cv r^2: {np.mean(cv_lm_lassotrain_r2s):.3f} +- {np.std(cv_lm_lassotrain_r2s):.3f}')
print(f'Lasso Val mean cv r^2: {np.mean(cv_lm_lasso_r2s):.3f} +- {np.std(cv_lm_lasso_r2s):.3f}')

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_test_scaled = scaler.transform(X_test)

#lm_ridge = Ridge(alpha=1)
lm_lasso.fit(X_scaled,y)
print(f'Lasso Regression test R^2: {lm_lasso.score(X_test_scaled, y_test):.3f}')

"""**Examining Outliers**"""

X, y = movies_intl.drop('worldwide_gross',axis=1), movies_intl['worldwide_gross']

X, X_test, y, y_test = train_test_split(X, y, test_size=.2, random_state=10)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=3)
preds = lm_lasso.predict(X_test)
residuals = preds - y_test
fig, ax = plt.subplots()
ax.scatter(y_test, residuals, alpha = .5)

"""**Regularization after dropping more outliers**"""

movies_2 = movies_intl[movies_intl['worldwide_gross'] < 1000000000]
movies_2.head()

lr_full = LinearRegression()

X = movies_2.drop('worldwide_gross',axis=1)
y = movies_2['worldwide_gross']

lr_full.fit(X, y)
lr_full.score(X, y)

sm.add_constant(X).head()

#Create the model
model = sm.OLS(y, sm.add_constant(X)) 

#Fit
fit = model.fit()

#Print out summary
fit.summary()

import statsmodels.api as sm



"""## **Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

[2] The condition number is large, 2.94e+10. This might indicate that there are
strong multicollinearity or other numerical problems.**
"""

X, y = movies_2.drop('worldwide_gross',axis=1), movies_2['worldwide_gross']
X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)
lr = LinearRegression()
lr.fit(X_train, y_train)
lr.score(X_train, y_train)

lr.score(X_val, y_val)

lr.coef_

preds = lr.predict(X_test)
residuals = preds - y_test
fig, ax = plt.subplots()
ax.scatter(y_test, residuals, alpha = .5)

X, y = movies_2.drop('worldwide_gross',axis=1), movies_2['worldwide_gross']

X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)
std = StandardScaler()
std.fit(X_train.values)

X_train_scaled = std.transform(X_train.values)
X_val_scaled = std.transform(X_val.values)
X_test_scaled = std.transform(X_test.values)
lasso_model = LassoCV()
lasso_model.fit(X_train_scaled, y_train)
lasso_model.score(X_train_scaled, y_train)

lasso_model.score(X_val_scaled, y_val)

list(zip(X_train.columns, lasso_model.coef_))

lasso_model.score(X_test_scaled, y_test)

X_scaled = std.transform(X)
lasso_model.score(X_scaled, y)

preds = lr.predict(X_test)
residuals = preds - y_test
fig, ax = plt.subplots()
ax.scatter(y_test, residuals, alpha = .5)

ridge_model = RidgeCV()
ridge_model.fit(X_train_scaled, y_train)
ridge_model.score(X_train_scaled, y_train)

ridge_model.score(X_val_scaled, y_val)

list(zip(X_train.columns, ridge_model.coef_))

poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_val_poly = poly.transform(X_val)
lm_poly = LinearRegression()
lm_poly.fit(X_train_poly, y_train)
lm_poly.score(X_train_poly, y_train)

lm_poly.score(X_val_poly, y_val)

"""# **Interpretation of Coefficients**"""

movies_2.describe()

movies_describe = movies_2.drop('worldwide_gross',axis=1).describe()
movies_describe

movies_describe.loc[['std']]

d = dict(list(zip(X_train.columns, lasso_model.coef_)))
movies_describe = movies_describe.T
movies_describe

movies_describe.drop(['count','mean','min','25%','50%','75%','max'], axis=1, inplace=True)
movies_describe.reset_index(inplace=True)
movies_describe['lasso_coeff'] = movies_describe['index'].map(d)
movies_describe

movies_describe['original_scale_coeff'] = (movies_describe['lasso_coeff'])/(movies_describe['std'])
movies_describe

pd.options.display.float_format = '{:.5f}'.format
movies_describe.round(5)

movies_describe.sort_values('original_scale_coeff',ascending=False)

"""## **Residuals vs. Predictions**"""

lr = LinearRegression()
fit = lr.fit(X, y)

preds = lr.predict(X)
residuals = preds - y
fig, ax = plt.subplots()
ax.scatter(y, residuals, alpha = .5)

ax.set_title("Residuals vs. Predictions")

"""# **RMSE**"""

import numpy as np
std_y = 183228936.57687
r_squared = 0.3142810036267232

RMSE = (np.sqrt(1 - r_squared)) * std_y
RMSE

from sklearn.metrics import mean_squared_error
lm = LinearRegression()
lm.fit(X, y)

y_pred = lm.predict(X_test)
rms = np.sqrt(mean_squared_error(y_test, y_pred))
print(rms)

"""# LARS Path"""

from sklearn.linear_model import lars_path
std = StandardScaler()
std.fit(X_train.values)

X_tr = std.transform(X_train.values)
print("Computing regularization path using the LARS ...")
alphas, _, coefs = lars_path(X_tr, y_train.values, method='lasso')

xx = np.sum(np.abs(coefs.T), axis=1)
xx /= xx[-1]

plt.figure(figsize=(10,10))
plt.plot(xx, coefs.T)
ymin, ymax = plt.ylim()
plt.vlines(xx, ymin, ymax, linestyle='dashed')
plt.xlabel('|coef| / max|coef|')
plt.ylabel('Coefficients')
plt.title('LASSO Path')
plt.axis('tight')
plt.legend(X_train.columns)
plt.show()

"""- Support
Contributions, issues, and feature requests are welcome!

- Give a STAR if you like this project! and FOLLOW do SUPPORT Friends.
 
- I hope you found the project useful and interesting.
- Feel free to contact me if you have any queries or suggestions... 
"""